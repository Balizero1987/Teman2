# Intel Scraper - Scheduled News Scraping
# Runs every 6 hours to scrape news from 630+ sources and send to BaliZero

name: Intel Scraper

on:
  # Run every 6 hours
  schedule:
    - cron: '0 */6 * * *'

  # Allow manual triggering
  workflow_dispatch:
    inputs:
      categories:
        description: 'Categories to scrape (comma-separated, empty for all)'
        required: false
        default: ''
      limit:
        description: 'Max items per category'
        required: false
        default: '10'
      dry_run:
        description: 'Dry run (no actual scraping)'
        required: false
        default: 'false'
        type: boolean

env:
  SCRAPER_API_URL: ${{ vars.SCRAPER_API_URL || 'https://bali-intel-scraper.fly.dev' }}
  BALIZERO_API_URL: ${{ vars.BALIZERO_API_URL || 'https://balizero.com' }}

jobs:
  scrape:
    name: Scrape News Sources
    runs-on: ubuntu-latest
    timeout-minutes: 30

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'

      - name: Trigger Scraping Job
        id: trigger
        run: |
          echo "üöÄ Triggering scraping job..."

          # Build request body
          CATEGORIES='${{ github.event.inputs.categories }}'
          LIMIT='${{ github.event.inputs.limit || 10 }}'

          if [ -n "$CATEGORIES" ]; then
            CATEGORIES_JSON=$(echo "$CATEGORIES" | jq -R 'split(",") | map(gsub("^\\s+|\\s+$";""))')
            REQUEST_BODY=$(jq -n \
              --argjson categories "$CATEGORIES_JSON" \
              --argjson limit "$LIMIT" \
              '{
                categories: $categories,
                limit: $limit,
                generate_articles: false,
                upload_to_vector_db: false,
                send_to_balizero: true
              }')
          else
            REQUEST_BODY=$(jq -n \
              --argjson limit "$LIMIT" \
              '{
                limit: $limit,
                generate_articles: false,
                upload_to_vector_db: false,
                send_to_balizero: true
              }')
          fi

          echo "Request body: $REQUEST_BODY"

          # Trigger the scraping job
          RESPONSE=$(curl -s -X POST \
            "${SCRAPER_API_URL}/api/v1/scrape/trigger" \
            -H "Content-Type: application/json" \
            -d "$REQUEST_BODY")

          echo "Response: $RESPONSE"

          JOB_ID=$(echo "$RESPONSE" | jq -r '.job_id // empty')

          if [ -z "$JOB_ID" ]; then
            echo "‚ùå Failed to trigger scraping job"
            echo "$RESPONSE" | jq .
            exit 1
          fi

          echo "‚úÖ Job triggered: $JOB_ID"
          echo "job_id=$JOB_ID" >> $GITHUB_OUTPUT

      - name: Wait for Job Completion
        id: wait
        run: |
          JOB_ID="${{ steps.trigger.outputs.job_id }}"
          MAX_WAIT=600  # 10 minutes max
          POLL_INTERVAL=15
          ELAPSED=0

          echo "‚è≥ Waiting for job $JOB_ID to complete..."

          while [ $ELAPSED -lt $MAX_WAIT ]; do
            STATUS_RESPONSE=$(curl -s "${SCRAPER_API_URL}/api/v1/scrape/jobs/${JOB_ID}")
            STATUS=$(echo "$STATUS_RESPONSE" | jq -r '.status // "unknown"')
            STAGE=$(echo "$STATUS_RESPONSE" | jq -r '.stage // "unknown"')

            echo "Status: $STATUS (stage: $STAGE)"

            if [ "$STATUS" == "completed" ]; then
              echo "‚úÖ Job completed successfully!"
              echo "$STATUS_RESPONSE" | jq '.results'
              break
            elif [ "$STATUS" == "failed" ]; then
              echo "‚ùå Job failed!"
              echo "$STATUS_RESPONSE" | jq '.error'
              exit 1
            fi

            sleep $POLL_INTERVAL
            ELAPSED=$((ELAPSED + POLL_INTERVAL))
          done

          if [ $ELAPSED -ge $MAX_WAIT ]; then
            echo "‚ö†Ô∏è Job timed out after ${MAX_WAIT}s"
            exit 1
          fi

      - name: Notify Success
        if: success()
        run: |
          echo "üì∞ Intel scraper completed successfully!"
          echo "Check pending news at: ${BALIZERO_API_URL}/news?admin=true"

      - name: Notify Failure
        if: failure()
        run: |
          echo "‚ùå Intel scraper failed. Check logs for details."
