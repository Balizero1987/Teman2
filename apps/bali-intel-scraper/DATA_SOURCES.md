# ğŸ“° Fonti Dati Intel Scraper

## ğŸ” Dove Trova le Informazioni nello Step Iniziale

Lo scraper trova le informazioni da **2 fonti principali**:

---

## 1ï¸âƒ£ **Google News RSS** (`rss_fetcher.py`)

### Come Funziona:
- **Fonte:** Google News RSS Feed
- **URL Base:** `https://news.google.com/rss/search`
- **Query:** Ricerca per topic specifici (vedi sotto)
- **Lingua:** Inglese + Bahasa Indonesia (`hl=en-ID&gl=ID&ceid=ID:en`)

### Topic Monitorati (20+ query):

#### Immigration
- `Indonesia visa KITAS regulation`
- `Bali visa immigration`
- `Indonesia golden visa`
- `digital nomad visa Indonesia`

#### Business
- `Indonesia PT PMA foreign investment`
- `Indonesia business regulation BKPM`
- `Bali business startup`
- `Indonesia KBLI OSS`

#### Tax
- `Indonesia tax regulation pajak`
- `Indonesia NPWP tax`
- `Indonesia corporate tax PPh`

#### Property
- `Bali property real estate`
- `Indonesia land ownership foreigner`
- `Bali villa investment`

#### Tech/AI
- `Indonesia AI artificial intelligence`
- `Indonesia startup technology funding`
- `Indonesia fintech digital economy`
- `Indonesia kecerdasan buatan`

#### Lifestyle
- `Bali expat news`
- `Bali digital nomad`

### Output RSS:
```json
{
  "title": "Article Title",
  "summary": "Article summary from RSS",
  "source": "Source Name",
  "sourceUrl": "https://...",
  "category": "immigration|business|tax|property|tech|lifestyle",
  "publishedAt": "2025-01-10T12:00:00Z"
}
```

---

## 2ï¸âƒ£ **790+ Fonti Web** (`unified_scraper.py` - BaliZeroScraperV2)

### Come Funziona:
- **Fonte:** Scraping diretto da siti web configurati
- **Config:** `config/unified_sources.json` + `config/extended_sources.json`
- **Metodo:** Web scraping con `SmartExtractor`
- **Categorie:** immigration, tax_bkpm, property, business, tech, etc.

### Esempio Configurazione:
```json
{
  "sources": [
    {
      "name": "Jakarta Post",
      "url": "https://www.thejakartapost.com",
      "category": "business",
      "tier": "T1",
      "selectors": {
        "title": "h1.article-title",
        "content": ".article-body"
      }
    }
  ]
}
```

---

## ğŸ”„ Flusso Completo

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 0: SEMANTIC DEDUPLICATION (Qdrant)                    â”‚
â”‚  âœ… Controlla se l'articolo Ã¨ giÃ  stato processato          â”‚
â”‚  âœ… Usa embedding vettoriale per similaritÃ  semantica       â”‚
â”‚  âœ… Se duplicato â†’ SKIP (risparmio $$$)                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“ (solo se NON duplicato)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  FONTE DATI:                                                 â”‚
â”‚                                                              â”‚
â”‚  MODE "quick" o "full":                                     â”‚
â”‚  â””â”€> Google News RSS (rss_fetcher.py)                      â”‚
â”‚      â””â”€> 20+ query per topic                                â”‚
â”‚      â””â”€> Professional scoring (5 dimensioni)               â”‚
â”‚                                                              â”‚
â”‚  MODE "massive":                                            â”‚
â”‚  â””â”€> 790+ fonti web (unified_scraper.py)                   â”‚
â”‚      â””â”€> Scraping diretto da siti configurati               â”‚
â”‚      â””â”€> SmartExtractor per estrazione contenuto            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 1: LLAMA SCORER                                       â”‚
â”‚  âœ… Scoring locale veloce (Ollama)                          â”‚
â”‚  âœ… Filtra noise (score < 40)                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 2-7: Pipeline completa...                            â”‚
â”‚  (Claude Validation â†’ Enrichment â†’ Images â†’ SEO â†’ etc.)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“‹ Quando Viene Eseguito Step 0?

**Step 0 (Semantic Deduplication) viene eseguito PRIMA di tutto:**

1. âœ… **Articolo arriva** (da RSS o web scraping)
2. âœ… **Step 0:** Controlla Qdrant per duplicati semantici
3. âœ… **Se duplicato:** SKIP immediato (non passa a Step 1)
4. âœ… **Se unico:** Continua con Step 1 (LLAMA Scoring)

### Codice (`intel_pipeline.py`):

```python
async def process_article(self, article: PipelineArticle):
    # STEP 0: SEMANTIC DEDUPLICATION (PRIMA DI TUTTO)
    logger.info("ğŸ§  Step 0: Semantic Deduplication Check...")
    try:
        is_dup, original_title, score = await self.deduplicator.is_duplicate(
            article.title,
            article.summary,
            article.url
        )
        if is_dup:
            logger.warning(f"ğŸ›‘ DUPLICATE DETECTED (Score: {score:.2f})")
            article.is_duplicate = True
            self.stats.dedup_filtered += 1
            return article  # â† SKIP, non processa oltre
    except Exception as e:
        logger.error(f"Dedup check failed (continuing safely): {e}")
    
    # STEP 1: LLAMA SCORING (solo se non duplicato)
    # ...
```

---

## ğŸ¯ ModalitÃ  di Esecuzione

### `--mode quick`
- **Fonte:** Solo Google News RSS
- **Step 0:** âœ… Deduplicazione semantica
- **Step 1:** âœ… LLAMA Scoring
- **Step 2+:** âŒ No enrichment (solo scoring + invio)

### `--mode full`
- **Fonte:** Google News RSS
- **Step 0:** âœ… Deduplicazione semantica
- **Step 1:** âœ… LLAMA Scoring
- **Step 2-7:** âœ… Pipeline completa (Claude enrichment, images, SEO, etc.)

### `--mode massive`
- **Fonte:** 790+ fonti web (scraping diretto)
- **Step 0:** âœ… Deduplicazione semantica
- **Step 1:** âœ… LLAMA Scoring
- **Step 2-7:** âœ… Pipeline completa

---

## ğŸ’¡ Vantaggi Step 0 (Semantic Deduplication)

1. **Risparmio Costi:** Filtra duplicati PRIMA di chiamare Claude ($0.01-0.05 per articolo)
2. **VelocitÃ :** Controllo rapido con Qdrant (millisecondi)
3. **Precisione:** SimilaritÃ  semantica (88% threshold) invece di solo URL matching
4. **Memoria:** Salva articoli approvati per deduplicazione futura

---

## ğŸ“Š Statistiche

- **RSS Topics:** 20+ query Google News
- **Web Sources:** 790+ siti configurati
- **Categorie:** immigration, business, tax, property, tech, lifestyle
- **Deduplicazione:** SimilaritÃ  semantica > 88% = duplicato
- **Window:** Controlla solo ultimi 5 giorni (configurabile)

---

**In sintesi:** Lo scraper trova le informazioni da Google News RSS (20+ topic) e/o 790+ fonti web. Lo Step 0 (Semantic Deduplication) viene eseguito **PRIMA** di tutto per filtrare duplicati e risparmiare costi.
